{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retroactively seeds metadata for MDI or HMI. Using the DRMS protocol='fits' is time consuming since a data export request is issued to JSOC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import drms\n",
    "import h5py\n",
    "import numpy as np\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "from Mission_utility.product_time_sync import csv_times_reader\n",
    "import json\n",
    "from astropy.io.fits import Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action = \"ignore\", category = FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(NpEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_header_local(mission, image_size_output, query, mag_keys):\n",
    "    \n",
    "    if mission == 'SOHO': \n",
    "        orig_img_size = 1024\n",
    "\n",
    "    elif mission == 'SDO':     \n",
    "        orig_img_size = 4096\n",
    "\n",
    "    rescale_factor = int(orig_img_size / image_size_output)\n",
    "    #print('rescale_factor:', rescale_factor)\n",
    "\n",
    "    for key in mag_keys:\n",
    "        \n",
    "        if (key == 'CDELT1') or (key == 'CDELT2'):\n",
    "            query[key] = query[key]*rescale_factor #this updates the original data frame\n",
    "        elif (key == 'CRPIX1') or (key == 'CRPIX2'):\n",
    "            query[key] = query[key]/rescale_factor\n",
    "        \n",
    "        try: \n",
    "            query['RSUN_OBS'] = query['RSUN_OBS']/rescale_factor \n",
    "            query['R_SUN'] = query['R_SUN']/rescale_factor\n",
    "            query['X0'] = query['X0']/rescale_factor \n",
    "            query['Y0'] = query['Y0']/rescale_factor \n",
    "            query['CROP_RAD'] = query['CROP_RAD']/rescale_factor\n",
    "            query['SOLAR_R'] = query['SOLAR_R']/rescale_factor\n",
    "        except KeyError:\n",
    "            pass\n",
    "                    \n",
    "    \n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Update as appropriate ###\n",
    "\n",
    "base = 'MDI_96m' # HMI_720s # MDI_96m\n",
    "mission = 'SOHO' #SDO #SOHO\n",
    "image_size_output = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = drms.Client()\n",
    "query_mag = 'mdi.fd_M_96m_lev182[]' ### or ('hmi.M_720s[]') if want SDO HMI instead of SOHO MDI\n",
    "mag_keys = client.query(query_mag, key=drms.const.all) \n",
    "print('len(mag_keys):', len(mag_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_keys_list = list(client.keys('mdi.fd_M_96m_lev182')) #or ('hmi.M_720s') if want SDO HMI instead of SOHO MDI\n",
    "print('mag_keys_list:', mag_keys_list)\n",
    "print('len(mag_keys_list):', len(mag_keys_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Path to MDI or HMI data cube that want to add metadata to retroactively ###\n",
    "### Be sure to include '/' at the end of every path variable\n",
    "\n",
    "path_to_mag_cube = '/home/carl/Documents/synced_1_3_7_experiments_calibrated/synced_1_3_7_experiments_calibrated_1_product_MDI_only/' \n",
    "mag_cube_name = '1999-02-02-16:00:00_to_2011-01-01-00:00:00_MDI_96m_subsample_6_LASCOlev1-N_SOHO_128.h5'\n",
    "cube_orig = h5py.File(f'{path_to_mag_cube}{mag_cube_name}','r') \n",
    "print(list(cube_orig.keys()))\n",
    "cube_orig_data = cube_orig[list(cube_orig.keys())[0]][:] ### this is more generic\n",
    "#cube_orig[f'{base}_{mission}_{image_size_output}'][:] ### this corresponds to the most updated nomenclature\n",
    "print('np.shape(cube_orig_data):', np.shape(cube_orig_data))\n",
    "\n",
    "times_list = csv_times_reader(path_to_mag_cube, pattern = f'*{base}*{mission}*[!sync].csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('times_list[0:10]:', times_list[0:10])\n",
    "print('times_list[-10:]:', times_list[-10:])\n",
    "print('np.shape(times_list):', np.shape(times_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Should  get as output:\n",
    "'MDI_96m_SOHO_128'\n",
    "np.shape(cube_orig_data): (15456, 128, 128)\n",
    "name from csv_times_reader: 1999-01-01_to_2010-12-31_MDI_96m_times_subsample_6_LASCOlev1-N_SOHO_128.csv\n",
    "len(csv_uniq_times): 15456\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### creat cube copy with data from original cube and add the metadata via attributes which can now write ###\n",
    "\n",
    "full_mag_cube_name = f'{path_to_mag_cube}{mag_cube_name}'\n",
    "mag_cube_name_new = full_mag_cube_name.split('.')[0] + '_retroactive_metadata.h5'\n",
    "print(mag_cube_name_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### tqdm generates nice progress bar ###\n",
    "\n",
    "data_cube_new = h5py.File(mag_cube_name_new,'w')\n",
    "data_cube_new.create_dataset(f'{base}_{mission}_{image_size_output}', data=cube_orig_data, compression=\"gzip\")\n",
    "\n",
    "counter = 0\n",
    "meta_data_dict = {}\n",
    "\n",
    "for t_pre in tqdm(times_list[0:2]): ###first two slices only [0:2] as demonstration\n",
    "    t_drms_split = str(drms.to_datetime(t_pre)).split(' ')\n",
    "    t_tai = '_'.join((t_drms_split[0].replace('-','.'),t_drms_split[1]))+'_TAI'\n",
    "    \n",
    "    print(t_tai)\n",
    "    ### this is the old method which was exponentially slowed down while running on JSOC ###\n",
    "    #query = client.query(f'mdi.fd_M_96m_lev182[{t_tai}]', key = client.keys('mdi.fd_M_96m_lev182'))\n",
    "    \n",
    "    query_pre = mag_keys.loc[mag_keys['T_REC'] == t_tai]\n",
    "    query = mag_keys.loc[query_pre.index[0]]\n",
    "    \n",
    "    query_metadata_update = downsample_header_local(mission, image_size_output, query, mag_keys)\n",
    "    print(query_metadata_update['T_REC'])\n",
    "    \n",
    "    for j, key in enumerate(mag_keys):\n",
    "        if (key == 'COMMENT') or (key == 'HISTORY'):\n",
    "            key1 = f'{key}{counter}'\n",
    "            #data_cube_new.attrs[f'{key1}_{counter}'] = query_metadata_update[key]      \n",
    "            meta_data_dict[f'{key1}_{counter}'] = query_metadata_update[key]      \n",
    "        \n",
    "        else:\n",
    "            #data_cube_new.attrs[f'{key}_{counter}'] = query_metadata_update[key]\n",
    "            #if type(query_metadata_update[key]) == 'int':\n",
    "            #    meta_data_dict[f'{key}_{counter}'] = int(query_metadata_update[key])\n",
    "            #else:\n",
    "            meta_data_dict[f'{key}_{counter}'] = query_metadata_update[key]\n",
    "    \n",
    "    #data_cube_new.attrs[f'COMMENT_{counter}'] = f'Zeros outside solar disk for {base}'\n",
    "    meta_data_dict[f'COMMENT_{counter}'] = f'Zeros outside solar disk for {base}'\n",
    "    \n",
    "    counter += 1\n",
    "    \n",
    "#data_cube_new.attrs.update(meta_data_dict)\n",
    "data_cube_new.create_dataset(f'{base}_{mission}_{image_size_output}_metadata', data=json.dumps(meta_data_dict, cls=NpEncoder))\n",
    "data_cube_new.attrs['NOTE'] = 'JSON serialization'\n",
    "data_cube_new.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cube_new.close() ### in case error encountered in above cell, need to close the cube first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  For the full data cubes, this retroactive metadata seeding can take several days. This is still currently faster than using the FITS protocol to fetch FITS files with metadata from JSOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(f'{mag_cube_name_new}', 'r') as hfile:\n",
    "    metadata = json.loads(hfile[f'{base}_{mission}_{image_size_output}_metadata'][()])\n",
    "    print('list(hfile.attrs.items()):', list(hfile.attrs.items()))\n",
    "    for k in metadata:\n",
    "        print(f'{k} => {metadata[k]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(metadata.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(metadata.values())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
